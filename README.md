# - 剧本助手 V6.6
TIME:2025/11/04
长文本自动拆分；调用大模型剧本改编
# 小说→短剧剧本 自动改编工具（按字数分集版）README

> 轻量单页网页（纯前端），上传长篇小说 TXT，一键按**字数**拆分为多集，自动调用大语言模型为**每集同时生成「大纲 + 剧本」**，支持暂停/续跑/终止、人工改写后重生、自检打分、最终按目标集数合并/拆分导出。内置“调试窗口”，可在线直接替换整页代码并自动打版本号。

---

## 主要功能

* **按字数分集**：设置“每集原文字数”，把整部小说直接切分为 N 集。
* **目标时长→目标字数**：设置“单集时长(分钟)”与“每分钟字数”，自动计算本集目标字数（默认 2×1000=2000 字）。
* **一次生成**：每集一次 API 调用，直接返回 JSON：`{"outline":"本集大纲","script":"本集剧本"}`。
* **自检与打分（可选）**：可设置剧本自检次数；自检会校对是否符合大纲/格式/目标字数（不少于目标的 80%），并给出 `score` 与 `reason`。
* **人工干预**：任意时刻**暂停**；可编辑本集**原文/大纲/剧本**后保存，并可“一键根据大纲重生剧本”或重生整集。
* **运行控制**：开始、暂停/继续、终止；终止后可下载已完成部分。
* **导出重排**：支持“最终输出集数”，对已完成剧本**合并或拆分**后重新编号打包导出。
* **实时反馈**：左侧有“运行日志”和“API 反馈”面板，展示阶段状态与模型返回长度等信息。
* **估算信息（精简）**：显示**平均每集**原文/发送/目标字数 + 总耗时、总费用（估算）。
* **余额查询（SiliconFlow）**：若使用 SiliconFlow，会尝试显示账户余额（受浏览器/CORS 影响）。
* **编码自适应**：TXT 自动嗅探 UTF-8/GB18030，避免中文乱码。
* **在线调试面板**：右下角“调试/编辑代码”可查看并**直接替换整页 HTML**，保存后自动刷新并在标题处显示版本时间（本地 `localStorage` 持久化）。

---

## 快速使用

1. **打开网页**：直接本地双击 `html`（或部署到任意静态站点）。
2. **设置 API**

   * “接口预设”选择：`SiliconFlow · DeepSeek-V3 / DeepSeek 官方 / OpenAI / 自定义`
   * 会自动填充 `API地址` 与 `模型名`，填入你的 `API Key`（**请勿将私钥提交到公共仓库**）。
3. **上传小说 TXT**

   * 若有乱码，可切换“文件编码”为 `GBK/GB18030` 后重传。
4. **分集与参数**

   * 设定 **每集原文字数**（如 12000），点“按字数分集”。
   * 设定 **单集时长**（如 2 分钟）与 **每分钟字数**（默认 1000），自动得到目标字数（约 2000）。
   * 调整 `max_tokens`（建议 ≥ 4096）、`temperature`、`top_p`、`API最大发送字数`（如 12000）。
5. **开始生成**

   * 点“开始生成”，每集会一次性生成“**大纲 + 剧本**”。
   * 根据 `剧本自检次数` 决定是否做自检与补写（保证不少于目标字数 80%）。
6. **人工干预**

   * 随时“暂停”，在右侧选中某集，编辑**原文/大纲/剧本**并**保存**。
   * 可“根据大纲重生本集”或“只重生本集剧本”。
7. **导出**

   * “最终输出集数”可设为不同于当前集数：

     * **更少**：按比率**合并**多集；
     * **更多**：将合并文本再**拆分**为更多集；
   * 点“打包输出”，得到整剧 TXT。
8. **调试/升级页面**

   * 右下“调试/编辑代码”→ 粘贴新 HTML → “保存并重载”，自动写入 `localStorage` 并更新右上角版本时间。

---

## 参数说明（常用）

* **每集原文字数**：按该字数切分小说原文（影响每集上下文信息量）。
* **单集时长(分) + 每分钟字数**：计算**目标剧本字数**；模型会尽量写满，且不低于目标的 80%。
* **max_tokens**：模型**输出上限**（含 JSON 包装 + 大纲 + 剧本），建议 4096 或更高。
* **temperature / top_p**：采样策略（越高越发散）。
* **API最大发送字数**：防止一次请求发送过长原文（超出将**截断**并提示）。
* **剧本自检次数**：0 表示不自检；≥1 会做 JSON 自检与补写、给出 `score` 和 `reason`。
* **价格(元/1k tok)** + **推理速度(tok/s)**：用于估算总费用与时间（仅展示，不参与请求）。

---

## 兼容的 API 预设（示例）

* **SiliconFlow (DeepSeek-V3)**

  * `API地址`：`https://api.siliconflow.cn/v1/chat/completions`
  * `模型名`：`deepseek-ai/DeepSeek-V3`
* **DeepSeek 官方**

  * `API地址`：`https://api.deepseek.com/chat/completions`
  * `模型名`：`deepseek-chat`
* **OpenAI**

  * `API地址`：`https://api.openai.com/v1/chat/completions`
  * `模型名`：如 `gpt-4o-mini` 等

> 也支持自定义任意 OpenAI-compatible endpoint。

---

## 使用建议

* 想要**更长**的每集剧本：

  1. 提高“每分钟字数”或“单集时长”；
  2. 提高 `max_tokens`（4096/6144/8192）；
  3. 将“每集原文字数”适当提高（如 15000），但别超过“API最大发送字数”。
* 生成速度慢/超时：

  * 适当降低“每集原文字数”或 `API最大发送字数`；
  * 提高超时阈值；
  * 分批运行（暂停→稍后继续）。
* JSON 解析失败：

  * 网络波动或模型输出夹杂说明文字；重试或增加 `max_tokens`；
  * 右侧可手动修正后“重生剧本”。

---

## 安全 & 隐私

* 网页为**纯前端**，默认不上传你的文本和密钥到第三方服务器（请求直发模型 API）。
* **不要把私有 API Key 写死在仓库**或公开 Demo，建议运行时手动输入。
* 浏览器本地使用 `localStorage` 存储你通过“调试窗口”保存的整页 HTML 与版本时间。

---

## 目录结构（建议）

```
/
├─ index.html     # 本项目单页（可改名）
└─ README.md      # 本说明
```

---

## Roadmap（可选）

* 支持“两次调用模式”（先出大纲，后出剧本）进一步拉满剧本长度上限
* 更多模型预设与并发控制
* 断点进度持久化 / 导出 JSON 项目文件

---

## 许可

自由用于个人/内部项目；若用于公开服务，请遵循各 API 提供商的使用条款与速率/费用限制。
